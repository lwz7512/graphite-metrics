### Default (baseline) configuration parameters.
### DO NOT ever change this config, use -c commandline option instead!


collectors:
  # Modules that collect the actual datapoints to be sent

  _default: # used as a base for all other sections here
    enabled: true
    # debug: # auto-filled from global "debug" section, if not specified

  cron_log:
    source: # must be filled with path to a log file
    aliases: # either [alias, regexp] or ["_" + regexp_group, regexp], see "_script" example below
      # - ['logrotate', '(^|\b)logrotate\b']
      # - ['locate', '(^|\b)updatedb\b']
      # - ['_script', '/etc/cron\.\w+/*(?P<script>\S+)(\s+|$)']
    lines: # only named regexp groups here are mandatory, all lines are optional
      init: 'task\[(\d+|-)\]: Queued\b[^:]*: (?P<job>.*)$'
      start: 'task\[(\d+|-)\]: Started\b[^:]*: (?P<job>.*)$'
      finish: 'task\[(\d+|-)\]: Finished\b[^:]*: (?P<job>.*)$'
      duration: 'task\[(\d+|-)\]: Finished \([^):]*\bduration=(?P<val>\d+)[,)][^:]*: (?P<job>.*)$'
      error: 'task\[(\d+|-)\]: Finished \([^):]*\bstatus=0*[^0]+0*[,)][^:]*: (?P<job>.*)$'
    xattr_name: user.collectd.logtail.pos # used to mark "last position" in sa logs

  slabinfo:
    include_prefixes: # takes priority over exclude_prefixes
    exclude_prefixes: ['kmalloc-', 'kmem_cache', 'dma-kmalloc-']
    pass_zeroes: False # to skip creating a lot metrics for always-0 (for particular hosts) slab counts

  cgacct:
    cg_root: /sys/fs/cgroup
    resource_controllers: ['cpuacct', 'memory', 'blkio'] # mapped to methods in cgacct.py

  sysstat:
    force_interval: true # skip intervals of different length than core.interval
    force_interval_fuzz: 10 # +/- % to consider acceptable interval fuzz
    sa_path: /var/log/sa
    rate: # see "graphite_metrics.collectors.rate_limit"
      limiting_enabled: true
      max_interval: 30 # cycles
      sampling: 3
    xattr_name: user.sa_carbon.pos # used to mark "last position" in sa logs

  iptables_counts:
    rule_metrics_path:
      # Files with "chain_name rule_no metric_name" lines for iptables/ip6tables
      ipv4: /var/lib/iptables/metrics.list
      ipv6: /var/lib/ip6tables/metrics.list
    # One of: pkt, bytes, both (metric.pkt + metric.bytes), both_flat (metric_pkt + metric_bytes)
    units: both_flat
    # Consider counter invalid (and skip it) if rule has changed without rule_metrics file update
    discard_changed_rules: true

  # self_profiling: # TODO
  #   main_loop: true
  #   collectors: true


processors:
  # Modules that process the datapoints before they are passed to sinks
  # Datapoints are passed to processors in the same order as they're specified here,
  #  with all the entry points without config section afterwards in no particular order
  # Passed a list of sinks along with the datapoints,
  #  so can facilitate filtering, by dropping particular sinks from the list

  _default: # used as a base for all other sections here
    enabled: true
    # debug: # auto-filled from global "debug" section, if not specified

  hostname_prefix:
    hostname: # uname(), if unset


sinks:
  _default: # used as a base for all other sections here
    # Default host/port for all sinks can be overidden by CLI flags
    host: localhost # can be specified as "host[:port]"
    default_port: 2003

    enabled: false # should be explicitly enabled
    # debug: # auto-filled from global "debug" section, if not specified

  carbon_socket:
    enabled: true # the only sink enabled by default
    max_reconnects: # before bailing out with the error
    reconnect_delay: 5 # seconds


loop:
  name: basic # entry point name to use, only one loop can be used
  interval: 60 # seconds


debug: # values here can be overidden by special CLI flags
  dry_run: false


logging: # see http://docs.python.org/library/logging.config.html
  # "custom" level means WARNING or DEBUG, depending on CLI options
  warnings: true # capture python warnings
  tracebacks: true # much easier to debug with these, but noisy and multiline
  version: 1
  formatters:
    basic:
      format: '%(asctime)s :: %(levelname)s :: %(name)s: %(message)s'
      datefmt: '%Y-%m-%d %H:%M:%S'
  handlers:
    console:
      class: logging.StreamHandler
      stream: ext://sys.stdout
      formatter: basic
      level: custom
    # file:
    #   class: logging.handlers.WatchedFileHandler
    #   filename: /var/log/harvestd.log
    #   formatter: basic
    #   encoding: utf-8
    #   level: DEBUG
  # loggers:
  #   graphite_metrics.collectors.irq:
  #     level: ERROR
  root:
    handlers: [console]
    level: custom
